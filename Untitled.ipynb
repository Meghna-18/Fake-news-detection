{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f6baf1-2c65-4508-84eb-bf2187e83e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e30fa5c-183d-42fe-bf7d-e84eee82bf19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2284bee0-2c77-4845-89a8-5dbd061b1ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4097028-3e02-4d99-9d37-227ed7b4aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"train.csv//train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "016eb98d-5127-49d3-8f16-18911b92d0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "427a3de9-e476-44d3-8312-02f30813405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop=['id','author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbe632a4-5457-4af4-b50d-991cc54341f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59679301-d473-4a43-ab1f-24a6aef24ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2                  Why the Truth Might Get You Fired   \n",
       "3  15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4  Iranian woman jailed for fictional unpublished...   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1efc6df6-0af6-4e1a-8ce0-b8e911152e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns=['title','text']\n",
    "target=['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96dcdf41-e227-406e-ace5-70b5bd1a96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[selected_columns]\n",
    "y=df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af36f041-4e21-4530-a4f4-c47caebd3307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2                  Why the Truth Might Get You Fired   \n",
       "3  15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4  Iranian woman jailed for fictional unpublished...   \n",
       "\n",
       "                                                text  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...  \n",
       "1  Ever get the feeling your life circles the rou...  \n",
       "2  Why the Truth Might Get You Fired October 29, ...  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ceb7614-f4fe-47af-8fed-7c995910140d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "379d8032-44ca-4be3-8568-1db0e7dfbece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learnNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading scikit_learn-1.5.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.1-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/11.0 MB 2.6 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/11.0 MB 8.1 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.8/11.0 MB 7.5 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/11.0 MB 6.2 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/11.0 MB 6.2 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/11.0 MB 6.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.5/11.0 MB 5.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.7/11.0 MB 4.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.9/11.0 MB 4.8 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.1/11.0 MB 4.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.1/11.0 MB 4.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.1/11.0 MB 4.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.4/11.0 MB 4.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.7/11.0 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.3/11.0 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.5/11.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.6/11.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.8/11.0 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.0/11.0 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.2/11.0 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.3/11.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.8/11.0 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.0/11.0 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.2/11.0 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.4/11.0 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.6/11.0 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.8/11.0 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.9/11.0 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.1/11.0 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.6/11.0 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.8/11.0 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.0/11.0 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.2/11.0 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.4/11.0 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.5/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.7/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.0/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.2/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.4/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.5/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.9/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.1/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.3/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.5/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.6/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.8/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.0/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.2/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.4/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/11.0 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 301.8/301.8 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.1 threadpoolctl-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7db74a3-6730-4c2a-a996-81fe46604bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1ea08aa-e4f0-4439-82fa-f814c2bb9bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8370982e-dad5-4e56-bde6-c17da6e5b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3269a879-d008-4c24-84c4-c677ad5316fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df=pd.DataFrame(X_data.toarray(),columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f9383ea-677c-464c-9310-7a46e57a35c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text  title\n",
       "0   0.0    1.0\n",
       "1   1.0    0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac4c1bb6-090f-466b-b871-bd76706052b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   text  title\n",
      "0   0.0    1.0\n",
      "1   1.0    0.0\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6978544-7366-4dfb-8f80-a0ef83598984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2928a0d-22d7-4a24-a675-cd0afb62b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['text']\n",
    "y = df[df.columns[2:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d7a854e-b944-4a02-9308-62b543d3b0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataset: 1300\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data (replace with your actual DataFrame)\n",
    "# df = pd.DataFrame({'comment_text': [...], ... })\n",
    "\n",
    "# Select the 'comment_text' and label columns\n",
    "x = df['text'].astype(str)  # Convert text to string to avoid any issues\n",
    "y = df[df.columns[2:]].values       # Assuming labels are in columns 2 and onwards\n",
    "\n",
    "# Handle missing values in 'comment_text' if necessary\n",
    "x = x.fillna('')  # Replace NaN with an empty string or some placeholder\n",
    "\n",
    "# Define TextVectorization layer\n",
    "MAX_FEATURES = 200000\n",
    "vectorizer = TextVectorization(\n",
    "    max_tokens=MAX_FEATURES,\n",
    "    output_sequence_length=1800,\n",
    "    output_mode='int'\n",
    ")\n",
    "\n",
    "# Adapt the vectorizer to the text data\n",
    "vectorizer.adapt(x)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorized_text = vectorizer(x)\n",
    "\n",
    "# Ensure vectorized_text is in the correct format for TensorFlow\n",
    "vectorized_text = tf.convert_to_tensor(vectorized_text)\n",
    "\n",
    "# Create a TensorFlow dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "\n",
    "# Dataset operations\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(160000)  # Adjust buffer size if needed\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(8)\n",
    "\n",
    "# Get the number of batches\n",
    "dataset_length = len(list(dataset))\n",
    "print(f\"Length of the dataset: {dataset_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86e52d13-9ca5-4f80-a213-fb70b7d57513",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('test.csv//test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e86e061-7585-4799-86e4-35ffdae937bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20800</td>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>David Streitfeld</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20802</td>\n",
       "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
       "      <td>Common Dreams</td>\n",
       "      <td>Videos #NoDAPL: Native American Leaders Vow to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20803</td>\n",
       "      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n",
       "      <td>Daniel Victor</td>\n",
       "      <td>If at first you don’t succeed, try a different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20804</td>\n",
       "      <td>Keiser Report: Meme Wars (E995)</td>\n",
       "      <td>Truth Broadcast Network</td>\n",
       "      <td>42 mins ago 1 Views 0 Comments 0 Likes 'For th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  20800  Specter of Trump Loosens Tongues, if Not Purse...   \n",
       "1  20801  Russian warships ready to strike terrorists ne...   \n",
       "2  20802  #NoDAPL: Native American Leaders Vow to Stay A...   \n",
       "3  20803  Tim Tebow Will Attempt Another Comeback, This ...   \n",
       "4  20804                    Keiser Report: Meme Wars (E995)   \n",
       "\n",
       "                    author                                               text  \n",
       "0         David Streitfeld  PALO ALTO, Calif.  —   After years of scorning...  \n",
       "1                      NaN  Russian warships ready to strike terrorists ne...  \n",
       "2            Common Dreams  Videos #NoDAPL: Native American Leaders Vow to...  \n",
       "3            Daniel Victor  If at first you don’t succeed, try a different...  \n",
       "4  Truth Broadcast Network  42 mins ago 1 Views 0 Comments 0 Likes 'For th...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dfe72219-fc47-4d69-af00-3edc6b0012f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "861babc3-e9b7-4e3e-9ce1-2177d4c9d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2cbefcae-9370-4a6e-bb83-c4ba6fa41f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataset: 325\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data (replace with your actual DataFrame)\n",
    "# df = pd.DataFrame({'comment_text': [...], ... })\n",
    "\n",
    "# Select the 'comment_text' and label columns\n",
    "x_test = df['text'].astype(str)  # Convert text to string to avoid any issues\n",
    "\n",
    "# Handle missing values in 'comment_text' if necessary\n",
    "x_test = x_test.fillna('')  # Replace NaN with an empty string or some placeholder\n",
    "\n",
    "# Define TextVectorization layer\n",
    "MAX_FEATURES = 200000\n",
    "vectorizer = TextVectorization(\n",
    "    max_tokens=MAX_FEATURES,\n",
    "    output_sequence_length=1800,\n",
    "    output_mode='int'\n",
    ")\n",
    "\n",
    "# Adapt the vectorizer to the text data\n",
    "vectorizer.adapt(x_test)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorized_text = vectorizer(x_test)\n",
    "\n",
    "# Ensure vectorized_text is in the correct format for TensorFlow\n",
    "vectorized_text = tf.convert_to_tensor(vectorized_text)\n",
    "\n",
    "# Create a TensorFlow dataset\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((vectorized_text))\n",
    "\n",
    "# Dataset operations\n",
    "dataset_test = dataset_test.cache()\n",
    "dataset_test= dataset_test.shuffle(160000)  # Adjust buffer size if needed\n",
    "dataset_test = dataset_test.batch(16)\n",
    "dataset_test= dataset_test.prefetch(8)\n",
    "\n",
    "# Get the number of batches\n",
    "dataset_length_test = len(list(dataset_test))\n",
    "print(f\"Length of the dataset: {dataset_length_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f6e041fc-404b-4f32-b265-470c12192e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 909\n",
      "Validation set length: 260\n",
      "Test set length: 130\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training, validation, and test sets\n",
    "train = dataset.take(int(len(dataset) * 0.7))\n",
    "val = dataset.skip(int(len(dataset) * 0.7)).take(int(len(dataset) * 0.2))\n",
    "test = dataset.skip(int(len(dataset) * 0.9)).take(int(len(dataset) * 0.1))\n",
    "\n",
    "# Verify the lengths\n",
    "print(f\"Training set length: {len(list(train))}\")\n",
    "print(f\"Validation set length: {len(list(val))}\")\n",
    "print(f\"Test set length: {len(list(test))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d358d2fc-c4d9-4739-9c3b-603afab3593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, None, 32)          6400032   \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 64)               16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,416,672\n",
      "Trainable params: 6,416,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, None, 32)          6400032   \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 64)               16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,424,992\n",
      "Trainable params: 6,424,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, None, 32)          6400032   \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 64)               16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,491,041\n",
      "Trainable params: 6,491,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dropout,Bidirectional,Dense,Embedding\n",
    "from tensorflow.keras.utils import plot_model\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_FEATURES+1, 32))\n",
    "\n",
    "model.add(Bidirectional(LSTM(32 , activation = 'tanh')))\n",
    "model.summary()\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "model.add(Dense(256,activation = 'relu'))\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "model.summary()\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6fba2905-5d8c-4c5c-843f-00b0704cb4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydot) (3.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3366141c-8328-44ad-b807-4b9b00c7db78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "909/909 [==============================] - 819s 894ms/step - loss: 0.1758 - val_loss: 0.0445\n",
      "Epoch 2/10\n",
      "909/909 [==============================] - 763s 839ms/step - loss: 0.0524 - val_loss: 0.1495\n",
      "Epoch 3/10\n",
      "909/909 [==============================] - 17246s 19s/step - loss: 0.0509 - val_loss: 0.0177\n",
      "Epoch 4/10\n",
      "909/909 [==============================] - 5274s 6s/step - loss: 0.0210 - val_loss: 0.0100\n",
      "Epoch 5/10\n",
      "909/909 [==============================] - 3823s 4s/step - loss: 0.0254 - val_loss: 0.0210\n",
      "Epoch 6/10\n",
      "909/909 [==============================] - 976s 1s/step - loss: 0.0134 - val_loss: 0.0031\n",
      "Epoch 7/10\n",
      "909/909 [==============================] - 706s 776ms/step - loss: 0.0065 - val_loss: 0.0086\n",
      "Epoch 8/10\n",
      "909/909 [==============================] - 1025s 1s/step - loss: 0.0077 - val_loss: 0.0057\n",
      "Epoch 9/10\n",
      "909/909 [==============================] - 1317s 1s/step - loss: 0.0188 - val_loss: 0.0214\n",
      "Epoch 10/10\n",
      "909/909 [==============================] - 7747s 9s/step - loss: 0.0055 - val_loss: 0.0032\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, epochs=10, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d874b92-d07e-44f6-9f10-444b2ffc8f5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = vectorizer('Russian warships ready to strike terrorists near Aleppo 08.11.2016 | Source: Source: Mil.ru Attack aircraft of the Russian aircraft carrier Admiral Kuznetsov get ready to strike terrorists positions in the vicinity of Aleppo, sources at the Russian Defense Ministry said, RBC reports. Insurgents attempts to break into Aleppo from outside are meaningless,\" the source said. The main task of the aircraft carrier aviation group is to strike missile and air blows on the terrorists , whose goal is to enter Aleppo. After the attacks on terrorists positions, one will have to forget about the support for insurgents from the outside, the source said. The Russian group in the Mediterranean Sea consists of the Admiral Kuznetsov aircraft carrier , the heavy nuclear missile cruiser Pyotr Velikiy (Peter the Great) and large anti-submarine ships Severomorsk and Vice-Admiral Kulakov. Russia has increased intelligence activities in Syria to establish the areas, where terrorists are concentrated, as well as the routes that they use to move from one area to another. The militants took advantage of the humanitarian pause and regrouped their forces to prepare for a new breakthrough into the eastern part of Aleppo,\" the source added. According to the source, Russia will use new weapons during the upcoming attacks on terrorists . It was said that the Russian warships in the Mediterranean Sea will launch Caliber cruise missiles, although it was not specified which ships would be responsible for the launches. Pravda.Ru Russian warships travel to Syria')\n",
    "res = model.predict(np.expand_dims(input_text,0))\n",
    "(res > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "19d68363-61c7-46a7-8d5e-c3415e3da806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradioNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading gradio-4.41.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (4.4.0)\n",
      "Collecting fastapi (from gradio)\n",
      "  Downloading fastapi-0.112.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.3.0 (from gradio)\n",
      "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Collecting huggingface-hub>=0.19.3 (from gradio)\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
      "  Downloading importlib_resources-6.4.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.1.4)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.9.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.24.3)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.7-cp311-none-win_amd64.whl.metadata (51 kB)\n",
      "     ---------------------------------------- 0.0/51.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 51.7/51.7 kB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (10.4.0)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "     ---------------------------------------- 0.0/125.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 125.2/125.2 kB 7.7 MB/s eta 0:00:00\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.6.0-py3-none-win_amd64.whl.metadata (25 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.1.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting fsspec (from gradio-client==1.3.0->gradio)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
      "  Downloading websockets-12.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.24.1->gradio) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Collecting filelock (from huggingface-hub>=0.19.3->gradio)\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.19.3->gradio)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic>=2.0->gradio)\n",
      "  Downloading pydantic_core-2.20.1-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting starlette<0.39.0,>=0.37.2 (from fastapi->gradio)\n",
      "  Downloading starlette-0.38.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-4.41.0-py3-none-any.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.6 MB 16.3 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.7/12.6 MB 9.1 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.9/12.6 MB 7.1 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.1/12.6 MB 6.2 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 5.7 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.4/12.6 MB 5.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.6/12.6 MB 5.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 5.0 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.0/12.6 MB 4.8 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.2/12.6 MB 4.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.4/12.6 MB 4.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.5/12.6 MB 4.6 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.7/12.6 MB 4.6 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.9/12.6 MB 4.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.1/12.6 MB 4.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.3/12.6 MB 4.4 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 4.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.6/12.6 MB 4.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.8/12.6 MB 4.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.0/12.6 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.2/12.6 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.4/12.6 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.5/12.6 MB 4.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.7/12.6 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.9/12.6 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.1/12.6 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.6/12.6 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.8/12.6 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.0/12.6 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.2/12.6 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.4/12.6 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.5/12.6 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.7/12.6 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.9/12.6 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.4/12.6 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.6/12.6 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.8/12.6 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.0/12.6 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.1/12.6 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.3/12.6 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.5/12.6 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.7/12.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.0/12.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.6/12.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.8/12.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.9/12.6 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.1/12.6 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.3/12.6 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.7/12.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.8/12.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.0/12.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.2/12.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.4/12.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.6/12.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.9/12.6 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
      "   ---------------------------------------- 0.0/318.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 318.7/318.7 kB 19.3 MB/s eta 0:00:00\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "   ---------------------------------------- 0.0/417.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 417.5/417.5 kB 13.1 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.2-py3-none-any.whl (34 kB)\n",
      "Downloading orjson-3.10.7-cp311-none-win_amd64.whl (137 kB)\n",
      "   ---------------------------------------- 0.0/137.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 137.3/137.3 kB ? eta 0:00:00\n",
      "Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "   ---------------------------------------- 0.0/423.9 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 297.0/423.9 kB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 423.9/423.9 kB 4.4 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.20.1-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 4.7 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.4/1.9 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.6/1.9 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.6/1.9 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.6/1.9 MB 4.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/1.9 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.3/1.9 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.5/1.9 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.7/1.9 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.8/1.9 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading ruff-0.6.0-py3-none-win_amd64.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/8.7 MB 7.4 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.5/8.7 MB 5.6 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.7/8.7 MB 5.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.9/8.7 MB 4.8 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.1/8.7 MB 4.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.3/8.7 MB 4.4 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.4/8.7 MB 4.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.6/8.7 MB 4.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.8/8.7 MB 4.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.0/8.7 MB 4.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.2/8.7 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.4/8.7 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.5/8.7 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.7/8.7 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.8/8.7 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.8/8.7 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.0/8.7 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.4/8.7 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.6/8.7 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.8/8.7 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.0/8.7 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.2/8.7 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.3/8.7 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.5/8.7 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.7/8.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.9/8.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.1/8.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.3/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.4/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.6/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.8/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.0/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.2/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.3/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.5/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.7/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.9/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.1/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.2/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.4/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.6/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.9/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.1/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.3/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.7/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.7/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 47.2/47.2 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.8/62.8 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading fastapi-0.112.1-py3-none-any.whl (93 kB)\n",
      "   ---------------------------------------- 0.0/93.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 93.2/93.2 kB ? eta 0:00:00\n",
      "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.9/97.9 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "   ---------------------------------------- 0.0/177.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 177.6/177.6 kB 10.5 MB/s eta 0:00:00\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "   ---------------------------------------- 0.0/240.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 240.7/240.7 kB 14.4 MB/s eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.38.2-py3-none-any.whl (72 kB)\n",
      "   ---------------------------------------- 0.0/72.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 72.0/72.0 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.4/78.4 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading websockets-12.0-cp311-cp311-win_amd64.whl (124 kB)\n",
      "   ---------------------------------------- 0.0/125.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 125.0/125.0 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.5/87.5 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pydub, websockets, tqdm, tomlkit, shellingham, semantic-version, ruff, python-multipart, pydantic-core, orjson, mdurl, importlib-resources, fsspec, filelock, ffmpy, click, annotated-types, aiofiles, uvicorn, starlette, pydantic, markdown-it-py, huggingface-hub, rich, gradio-client, fastapi, typer, gradio\n",
      "Successfully installed aiofiles-23.2.1 annotated-types-0.7.0 click-8.1.7 fastapi-0.112.1 ffmpy-0.4.0 filelock-3.15.4 fsspec-2024.6.1 gradio-4.41.0 gradio-client-1.3.0 huggingface-hub-0.24.5 importlib-resources-6.4.2 markdown-it-py-3.0.0 mdurl-0.1.2 orjson-3.10.7 pydantic-2.8.2 pydantic-core-2.20.1 pydub-0.25.1 python-multipart-0.0.9 rich-13.7.1 ruff-0.6.0 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.38.2 tomlkit-0.12.0 tqdm-4.66.5 typer-0.12.3 uvicorn-0.30.6 websockets-12.0\n"
     ]
    }
   ],
   "source": [
    "pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7d789162-ff87-40c3-bf4d-93bb2da0ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'model' is your Keras model\n",
    "model.save('my_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eaae21c2-0196-44e7-8bad-76e61579141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "135298f3-04c4-47c9-8d6f-8ca163eb5ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Define the function to use the model for prediction\n",
    "def fake_news_detector(text):\n",
    "    # Preprocess the text as required by your model\n",
    "    # For example, tokenization and padding:\n",
    "    \n",
    "    # tokenized_text = tokenizer.texts_to_sequences([text])\n",
    "    # padded_text = tf.keras.preprocessing.sequence.pad_sequences(tokenized_text, maxlen=100)\n",
    "    \n",
    "    # Get the prediction\n",
    "    res = model.predict(np.expand_dims(input_text,0))\n",
    "    if(int(np.round(res[0]) == 0)):\n",
    "       return \"Reliable\"\n",
    "    else:\n",
    "       return \"Unreliable\"\n",
    "    \n",
    "    # Convert prediction to binary: 0 for reliable, 1 for unreliable\n",
    "    # return int(np.round(res[0]))\n",
    "\n",
    "# Create the Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=fake_news_detector,  # The function that uses your model\n",
    "    inputs=\"text\",          # Text input\n",
    "    outputs=\"label\",        # Label output for 0 or 1\n",
    "    title=\"Fake News Detector\",\n",
    "    description=\"Enter a news headline or text, and the model will classify it as reliable or unreliable.\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ced7f0-1592-44bd-800d-d424b343fbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
